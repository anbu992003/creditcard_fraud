{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Hjg9y2D-bAg"
   },
   "source": [
    "## Module 3.3: VAEs for Synthetic Data Generation\n",
    "\n",
    "We will create a variational auto-encoder that we will use to generate synthetic images.\n",
    "\n",
    "We will:\n",
    "- Implement the VAE architecture in Keras.\n",
    "- Train our model.\n",
    "- Use our model to generate synthetic data based on the dataset in general.\n",
    "- Use our model to generate synthetic data similar to particular data cases.\n",
    "\n",
    "Note that we will not spend time tuning hyper-parameters: The purpose is to show how different techniques can be implemented in Keras, not to solve particular data science problems as optimally as possible. Obviously, most techniques include hyper-parameters that need to be tuned for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iv45ShI2DzVR"
   },
   "source": [
    "We import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mwSMqexN-bAi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.backend import random_normal\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import itertools\n",
    "from collections import Counter\n",
    "np.random.seed(2)\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DkN_sgP2D87K"
   },
   "source": [
    "We will again be working with the MNIST data. These are 28x28 greyscale images of handwritten digits (0-9). The classes are the digit.\n",
    "\n",
    "This time we will be working with the input data as vectors, but still need to normalize the pixel values to real numbers between 0 and 1. Below we create a function that will do this, then call it.\n",
    "\n",
    "If you want to look at the data, examine the code in module 2.4, as this provides functions for viewing the MNIST images with their class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXfO7neT-bAm"
   },
   "outputs": [],
   "source": [
    "def get_data():\n",
    "  df=pd.read_csv('C:/Users/admin/Downloads/creditcard.csv')\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  df['Amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "  X=df.iloc[:,1:30]\n",
    "  y=df.iloc[:,-1]\n",
    "\n",
    "\n",
    "  x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    \n",
    "  return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nhyov8V0EdY3"
   },
   "outputs": [],
   "source": [
    "x_train,y_train,x_test,y_test=get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199364, 29), (199364,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199364, 29), (199364,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AQNkxTfGEoxG"
   },
   "source": [
    "Now we will create a function that defines, creates and compiles our VAE model. \n",
    "\n",
    "We will encode our data in a 2d Gaussian with independent variance. This means we have four parameters - 2 mean parameters and 2 standard deviation parameters. We will specify the prior to be a 2d standard normal distribution (i.e. with independent variance/standard deviation of 1).\n",
    "\n",
    "We will use the Kullback-Leibler divergence as the distribution loss. This is a measure of divergence of one distribution from another (from the perspective of the second - read up online to learn more), and we will use it to penalize encodings that diverge too far from the standard normal. This will enable us to generate synthetic data via samples from the 2d standard normal later.\n",
    "\n",
    "For ease of use, we will return five models: \n",
    "- A distributional encoder, that encodes an image as a distribution.\n",
    "- A probablistic encoder, that encodes the image as a vector sampled *from* the encoded distribution.\n",
    "- A decoder that reconstructs the image from the encoded distribution.\n",
    "- A decoder that reconstructs the images from a sample *from* the encoded distribution\n",
    "- The complete VAE. \n",
    "\n",
    "The comments in the code include more information, so read over them as you proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0C9GKXU-bAo"
   },
   "outputs": [],
   "source": [
    "# We pass dimensions and optimizer as arguments so code can be reused \n",
    "# with freedom. However note that we want a latent dimension of 2 \n",
    "# in order to give 2d plots later, and need the input dimension to be\n",
    "# 784 to work with Mnist digit images.\n",
    "def get_vae (\n",
    "    latent_dim=2,\n",
    "    intermediate_dim=9,\n",
    "    input_dim=28, # Mnist digit size\n",
    "    optimizer= Adam(lr = 0.001)\n",
    "):    \n",
    "    # Create the encoding layers\n",
    "    # Our encoder will have a single hidden layer, leading to the mean and variance layers.\n",
    "    encoder_input = Input((input_dim,))\n",
    "    encoder_hidden = Dense(intermediate_dim, \n",
    "                           activation='relu')(encoder_input)\n",
    "    encoder_mean = Dense(latent_dim)(encoder_hidden)\n",
    "    encoder_log_var = Dense(latent_dim)(encoder_hidden)\n",
    "\n",
    "    # We want to include a component of our loss function that penalizes\n",
    "    # the encoding distribution for its KL-divergence from our chosen prior.\n",
    "    # This can be done with the following custom layer:\n",
    "    class KLDivergenceLayer(Layer):\n",
    "        \"\"\" \n",
    "        Identity transform layer that adds KL divergence\n",
    "        to the final model loss.\n",
    "        \"\"\"\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            self.is_placeholder = True\n",
    "            super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "        def call(self, inputs):\n",
    "            mean, log_var = inputs\n",
    "            # We calculate the KL divergence from our chosen \n",
    "            # prior (2-d standard normal).            \n",
    "            kl_loss = - .5 * K.sum(1 + log_var -\n",
    "                                    K.square(mean) -\n",
    "                                    K.exp(log_var), axis=-1)\n",
    "            # The add_loss function means that this will be added\n",
    "            # to the final model loss when a model with this layer\n",
    "            # is compiled.\n",
    "            self.add_loss(K.mean(kl_loss), inputs=inputs)\n",
    "            # We return the inputs unchanged.\n",
    "            return inputs\n",
    "        \n",
    "    # We add our custom KLDivergenceLayer to the model.\n",
    "    encoder_mean2, encoder_log_var2 = KLDivergenceLayer()(\n",
    "        [encoder_mean, encoder_log_var])\n",
    "    \n",
    "    # To begin the decoding component we want to sample from the \n",
    "    # latent distribution generated by the variational encoder.\n",
    "    # We define a function that can do this to use in a Lambda layer.\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon_std=1.0\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                                  stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    \n",
    "    # And we add the lambda layer to the model graph\n",
    "    sampled = Lambda(sampling)([encoder_mean2,encoder_log_var2])    \n",
    "\n",
    "    # We instantiate these layers separately so as to reuse them later\n",
    "    # (Not so important to do the sampling layer, since it has no weights)\n",
    "    decoder_hidden_layer = Dense(intermediate_dim, activation='relu')\n",
    "    decoder_output_layer = Dense(input_dim, activation='sigmoid')\n",
    "    # And now use them to continue the vae model graph\n",
    "    decoder_hidden = decoder_hidden_layer(sampled)\n",
    "    decoder_output = decoder_output_layer(decoder_hidden)\n",
    "\n",
    "    # Now we can define our full VAE\n",
    "    vae = Model(encoder_input, decoder_output)\n",
    "    \n",
    "    # We have the KL-divergence loss specified inside the KLD layer. But we\n",
    "    # need a reconstruction loss. We will use negative log likelihood (and there\n",
    "    # are good theoretical reasons for this), but need to wrap it as so:\n",
    "    def nll(y_true, y_pred):\n",
    "        # keras.losses.binary_crossentropy gives the mean\n",
    "        # over the last axis. we require the sum\n",
    "        return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "    # Now we compile the variational auto-encoder.\n",
    "    vae.compile(optimizer=optimizer, loss=nll)\n",
    "    \n",
    "    # For ease, we will also specify encoder and decoder sub-models.\n",
    "    # First we specify the variational encoder, that encodes the input\n",
    "    # as a distribution.\n",
    "    dist_encoder = Model(encoder_input,[latent_mean,latent_log_var])\n",
    "    # Then we specify a probabilistic encoder. This will \n",
    "    # probabilisitcally project inputs on the latent space - ie\n",
    "    # it gives a probabilistic encoding (not a distribution, but a \n",
    "    # sample from the distribution)\n",
    "    encoder = Model(encoder_input, sampled)\n",
    "    \n",
    "    # Now we build a digit generator that can sample from the learned \n",
    "    # distribution. Note we use the same layers, so when they are\n",
    "    # trained while training the VAE, the stand alone decoder will\n",
    "    # be trained as well.\n",
    "    decoder_point_input = Input(shape=(latent_dim,))\n",
    "    decoder_hidden_b = decoder_hidden_layer(decoder_point_input)\n",
    "    decoder_output_b = decoder_output_layer(decoder_hidden_b)\n",
    "    generator = Model(decoder_point_input, decoder_output_b)\n",
    "    \n",
    "    # We will also want to generate synthetic based on \n",
    "    # posteriors from known images. In this case the generated \n",
    "    # images will be similar to the image that generated the posterior \n",
    "    # (the posterior will be generated from the image via the encoder).\n",
    "    decoder_dist_mean_input = Input(shape=(latent_dim,))\n",
    "    decoder_dist_log_var_input = Input(shape=(latent_dim,))\n",
    "    decoder_sampled = Lambda(sampling)([decoder_dist_mean_input,decoder_dist_log_var_input])    \n",
    "    decoder_hidden_d = decoder_hidden_layer(decoder_sampled)\n",
    "    decoder_output_d = decoder_output_layer(decoder_hidden_d)\n",
    "    post_generator = Model([decoder_dist_mean_input,decoder_dist_log_var_input], decoder_output_d)\n",
    "        \n",
    "    # Return our models\n",
    "    return vae,encoder,dist_encoder,generator,post_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4rACnVoIhBU"
   },
   "source": [
    "We call the above function and get our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAPODzNh-bAr"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latent_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f9268f1b61f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvae\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdist_encoder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpost_generator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_vae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-2a78840125e7>\u001b[0m in \u001b[0;36mget_vae\u001b[1;34m(latent_dim, intermediate_dim, input_dim, optimizer)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;31m# First we specify the variational encoder, that encodes the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# as a distribution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[0mdist_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlatent_mean\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlatent_log_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m     \u001b[1;31m# Then we specify a probabilistic encoder. This will\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;31m# probabilisitcally project inputs on the latent space - ie\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'latent_mean' is not defined"
     ]
    }
   ],
   "source": [
    "vae,encoder,dist_encoder,generator,post_generator=get_vae()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-34XZRtIybA"
   },
   "source": [
    "Now we create function to train the model - it is just a wrapper for the Keras train function. We will perform early stopping with patience 10 and use the test data as validation data. Remember, since this is an auto-encoder the target variables are just the input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTTRrh09KJd0"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "  vae,\n",
    "  x_train,\n",
    "  x_test,\n",
    "  batch_size = 100\n",
    "  epochs = 200\n",
    "):\n",
    "  early_stopping=EarlyStopping(\n",
    "      monitor='val_loss', \n",
    "      patience=10, \n",
    "      verbose=2,\n",
    "      restore_best_weights=True\n",
    "  )\n",
    "  # We need to train the variational auto-encoder before anything else!\n",
    "  train_history=vae.fit(\n",
    "      x_train,\n",
    "      x_train,\n",
    "      shuffle=True,\n",
    "      epochs=epochs,\n",
    "      batch_size=batch_size,\n",
    "      validation_data=(x_test, x_test),\n",
    "      callbacks=[early_stopping]\n",
    "  )\n",
    "  return train_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AeMczhpAJLKQ"
   },
   "source": [
    "Now we train our model. You can graph the training history as an exercise if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vVFXrJyW-bAu",
    "outputId": "e6520e26-ece4-43f0-c1b8-2339513c20f8"
   },
   "outputs": [],
   "source": [
    "train_history=train(vae,x_train,x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_59YojoLJrFE"
   },
   "source": [
    "Let's create and then call a function that will graph the probabilistic encodings of the test images (remember these are the vector encodings sampled from the distributional encodings for each image). We would like to see good clusters for the different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bwzG33E5-bAx"
   },
   "outputs": [],
   "source": [
    "def display_embeddings(\n",
    "    encoder,\n",
    "    test_x,\n",
    "    test_y,\n",
    "    batch_size\n",
    "):\n",
    "    # display a 2D plot of the digit classes in the encoding space\n",
    "    x_test_encoded = encoder.predict(test_x, batch_size=batch_size)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=test_y)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cqpYWB7-bAy",
    "outputId": "5f9872a7-9842-40b5-a023-0d2db651552c"
   },
   "outputs": [],
   "source": [
    "display_embeddings(encoder,x_test,y_test,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6sUtEfRKaS0"
   },
   "source": [
    "Now let's have a look at the images reconstructed from different points in our prior. (Remember we will be sampling from the prior to generate different synthetic images - so we would like to see different images clustered at different locations). We can generate these images by picking a grid of points within the high-probability region of the 2d standard normal and passing these to the (vector) decoder for reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FGApI0EU-bA1"
   },
   "outputs": [],
   "source": [
    "# We pass image dimensions as arguments so code can be reused with\n",
    "# more freedom. However note that we need 28 by 28 to work with \n",
    "# Mnist digit images.\n",
    "def display_distribution_images (\n",
    "    generator,\n",
    "    image_width = 28,\n",
    "    image_height = 28\n",
    "):\n",
    "    # display a 2D manifold of the digits\n",
    "    n = 15  # figure with 15x15 digits\n",
    "    figure = np.zeros((image_width * n, image_height * n))\n",
    "    # linearly spaced coordinates on the unit square were transformed \n",
    "    # through the inverse CDF (ppf) of the Gaussian to produce values \n",
    "    # of the latent variables z, since the prior of the latent space is \n",
    "    # Gaussian\n",
    "    grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "    grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            latent_sample = np.array([[xi, yi]])\n",
    "            decoded = generator.predict(latent_sample)\n",
    "            digit = decoded[0].reshape(image_width, image_height)\n",
    "            figure[i * image_width: (i + 1) * image_width,\n",
    "                   j * image_height: (j + 1) * image_height] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-mzzt7YA-bA3"
   },
   "source": [
    "Let's have a look at the images generated at different poins in the prior distribution. You can see that similar digits struggle to be differentiated (3 & 8, 4 & 9), but it is pretty impressive for our quick attempt. It may be that having a larger latent dimension would help this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84yf8-cs-bA3",
    "outputId": "a5697541-d75e-405d-e2fe-eb17abd86782",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_distribution_images(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H3yGgpGT-bA5"
   },
   "source": [
    "Now let's see what happens when we generate 100 random images from the prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_fOmQd5-bA6"
   },
   "outputs": [],
   "source": [
    "# We pass image dimensions as arguments so code can be reused with\n",
    "# more freedom. However note that we need 28 by 28 to work with \n",
    "# Mnist digit images.\n",
    "\n",
    "# Display a 2D set of synthetic digits of size n x n.\n",
    "def generate_synthetic_data (\n",
    "    generator,\n",
    "    mean=np.array([0,0]),\n",
    "    log_var=np.array([0,0]),\n",
    "    n=10\n",
    "):    \n",
    "    # Note the Mnist image dimension is hardcoded here.\n",
    "    image_dim=28\n",
    "    \n",
    "    # Transform log variance to standard deviation\n",
    "    std_dev=np.exp(.5*log_var)\n",
    "    figure = np.zeros((image_dim * n, image_dim * n))\n",
    " \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            latent_sample=np.array([[rng.normal(mean[i],std_dev[i]) for \n",
    "                                    i in range(2)]])\n",
    "            decoded = generator.predict(latent_sample)\n",
    "            digit = decoded[0].reshape(image_dim, image_dim)\n",
    "            figure[i * image_dim: (i + 1) * image_dim,\n",
    "                   j * image_dim: (j + 1) * image_dim] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oh753tqv-bA7",
    "outputId": "484b66e8-31ef-4f2b-8b2c-cbec69566637"
   },
   "outputs": [],
   "source": [
    "generate_synthetic_data(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YEp1gK6L-bA9"
   },
   "source": [
    "Finally let's generate synthetic data that is like some particular labelled image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_6U-VBj-bA-"
   },
   "outputs": [],
   "source": [
    "def generate_synthetic_data_from_image(\n",
    "    dist_encoder,\n",
    "    generator,\n",
    "    image,\n",
    "    n=10\n",
    "):\n",
    "    mean,log_var=dist_encoder.predict(image)\n",
    "    generate_synthetic_data(generator,mean[0],log_var[0],n)\n",
    "\n",
    "def find_sample_image(\n",
    "    image_set, # The image set (e.g. x_test)\n",
    "    classes, # The labels for the image set\n",
    "    digit, # The class you want\n",
    "    rand=True # If False the first example of the class is chosen\n",
    "):\n",
    "    instances=np.where(classes==digit)[0]\n",
    "    if rand:\n",
    "        instance=rng.choice(instances,1)\n",
    "    else:\n",
    "        instance=instances[0]\n",
    "    return image_set[instance,:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGnynclf-bBA",
    "outputId": "f5280d36-7988-4bc5-eb04-ebd89e6bdcb5"
   },
   "outputs": [],
   "source": [
    "image=find_sample_image(x_test,y_test,4)\n",
    "generate_synthetic_data_from_image(dist_encoder,\n",
    "    generator,\n",
    "    image)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "vae.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
